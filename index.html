<!DOCTYPE HTML>
<!--
	Stellar by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
	Used for SIAM 2022
-->
<html>
<head>
    <title>SIAM 2023 workshop</title>
    <meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no"/>
    <link rel="stylesheet" href="assets/css/main.css"/>
    <noscript>
        <link rel="stylesheet" href="assets/css/noscript.css"/>
    </noscript>
</head>
<body class="is-preload">

<!-- Wrapper -->
<div id="wrapper">

    <!-- Header -->
    <header id="header" class="alt">
        <!--        <span class="logo"><img width="120px" src="images/siam-logo.svg" alt=""/></span>-->
        <h1>1st International Workshop on <br/> <strong>Socially Interactive Autonomous Mobility (SIAM)</strong></h1>
        <p>2023 IEEE Intelligent Vehicles Symposium (IV)</br>Anchorage, Alaska, USA June 4, 2023 <br/>
            Recording: <a href="https://www.youtube.com/@SIAMWorkshop">SIAM
                YouTube channel</a>
        </p>
        <!--        <strong> Time: half day on Sunday June 04, 2023. </br> Location: TBD.</strong>-->
    </header>

    <!-- Nav -->
    <nav id="nav">
        <ul>
            <li><a href="#intro" class="active">About</a></li>
            <li><a href="#Call for paper" class="active">Call for paper</a></li>
            <li><a href="#program" class="active">Program</a></li>
            <li><a href="#Invited_Speaker" class="active">Speakers</a></li>
            <li><a href="#Technical_Committee" class="active">Committee</a></li>
            <li><a href="#organizers" class="active">Organizers</a></li>
            <li><div class="dropdown">
                <button class="dropbtn">Previous</button>
                <div class="dropdown-content">
                    <a href="index_IV23.html">1st SIAM (IV23')</a>
                </div>
            </div></li>
        </ul>
    </nav>

    <!-- Main -->
    <div id="main">

        <!-- Introduction -->
        <section id="intro" class="main">
            <div class="spotlight">
                <div class="content">
                    <header class="major">
                        <h2>About</h2>
                    </header>
                    <p>One of the main goals of our workshop is to bridge the gap between Computational Cognitive &
                        Behavior Science, Explainable AI, Transportation, and the Autonomous Driving community.
                        Our SIAM workshop mainly targets theoretical frameworks and practical algorithms of perception,
                        decision-making, and planning integrated with social factors and computational cognitive science
                        to enable autonomous vehicles (AVs) to interact with human agents in a socially compatible way.
                        Specifically, the topics are as follows, but not limited to:
                    <ul>
                        <li>Applications of AVs interacting with human agents;</li>
                        <li>Algorithms of perception, decision-making, planning for human-like AVs;</li>
                        <li>Cognitive aspects and models for autonomous driving;</li>
                        <li>Cognitive and mental modeling toward socially driving, e.g., Theory of Mind and Theory of
                            Machine;
                        </li>
                        <li>Social cues for AVs in interactive driving tasks;</li>
                        <li>Action-reaction cycle modeling and validation;</li>
                        <li>Explainable interaction and planning in interactive driving tasks;</li>
                        <li>Evaluation and quantification of inter-human interactions and their implementations to
                            human-AV interactions;
                        </li>
                        <li>Human driving behavior/intention modeling, simulation, and analysis;</li>
                        <li>Heterogeneous human-agent teams;</li>
                        <li>Interactive traffic scenes analysis;</li>
                        <li>Interaction pattern learning, extraction, and recognition;</li>
                        <li>Interactive simulations and humans-in-the-loop simulations;</li>
                        <li>Learning-based theory for social interaction among human drivers;</li>
                        <li>Social and group intelligence in multiple human agent interaction;</li>
                        <li>Spatiotemporal driving behaviors in interactive traffic scenes;</li>
                    </ul>

                    </p>
                    <ul class="actions">
                        <li><a href="learn_more.html" class="button">Learn More</a></li>
                    </ul>
                </div>
                <!--                <span class="image"><img src="images/....png" alt=""/></span>-->
            </div>
        </section>

        <section id="Call for paper" class="main style1">
            <div class="container">
                <header class="major">
                    <h2>Call for paper</h2>
                </header>

                <p>Authors are invited to submit full-length papers up to 6 pages for technical content including
                    figures and references. Additional pages will be charged at the rate of $100 per page and is limited
                    to two pages per paper. Each paper will undergo a peer-reviewing process by at least two
                    independent reviewers. Contributions will be reviewed according to relevance, originality and novel
                    ideas, technical soundness and quality of presentation. Each accepted paper must be covered by at
                    least one non-studentregistration. Additional papers by the same authors will be charged at the flat
                    rate of $400 per paper.

                    To maximize visibility and impact, all accepted papers will be published in IEEE Xplore digital
                    library through Open Preview and will be freely accessible and downloadable by all, in final format,
                    beginning one month prior to the conference and through the conference end date.</p>

                <ul>
                    <strong>Submission:</strong>
                    <li> The submission portal is now open and authors can submit workshop papers.
                        This year we will not have workshop codes, rather authors follow the submission link (<a
                                href="https://edas.info/newPaper.php?c=30459&track=115618">
                            https://edas.info/newPaper.php?c=30459&track=115618 </a>) and select the
                        corresponding workshop from the list.
                    </li>

                    <li> Furthermore, here is the link with for the paper submission instructions with necessary
                        screenshots:
                        <a href="https://2023.ieee-iv.org/paper-submission/">
                            https://2023.ieee-iv.org/paper-submission/ </a>.
                    </li>
                </ul>

                <ul>
                    <strong>Finance:</strong>
                    <li>
                        Registration for attending the workshop-day only will be for a separate fee, <strong>except for
                        IEEE ITSS members</strong>, they will receive free attendance to the workshop-day.
                    </li>
                    <li>
                        In case of accepted workshop paper, one author has to pay the full publication fee to include
                        the
                        paper into the proceedings.
                    </li>
                </ul>

                <ul><strong>Important Deadlines:</strong>
                    <li><strong>February 01, 2023 (firm deadline, no extension):</strong> Workshop
                        Paper Submission Deadline
                    </li>
                    <li><strong>March 30, 2023:</strong> Workshop Paper Notification of
                        Acceptance
                    </li>
                    <li><strong>April 22, 2023:</strong> Workshop Final Paper Submission Deadline
                    </li>
                </ul>
            </div>
        </section>


        <section id="program" class="main style1">
            <div class="container">
                <header class="major">
                    <h2>Program (8:30 a.m. - 12:45 p.m., June 4th, 2023)</h2>
                </header>

                <p>The program of this workshop includes 7 talks in several sessions. </br>
                    - The talks will be streaming online via: <a href="https://mcgill.zoom.us/j/81817355928">zoom
                        meeting</a>.</br>
                    - Recordings of all talks will be available on the <a href="https://www.youtube.com/@SIAMWorkshop">SIAM
                        YouTube channel</a>.</br>
                    - ðŸ‘‰ Check out our <a href="./files/SIAM_Workshop_IV23_Flyer.pdf">Flyer</a>!
                </p>

                <div class="table-wrapper">
                    <table>
                        <thead>
                        <tr>
                            <th>Time</th>
                            <th>Speaker</th>
                            <th>Topic (click to see more details)</th>
                        </tr>
                        </thead>
                        <tbody>

                        <tr>
                            <td>8:30-8:35</td>
                            <!--                            <td> 4:30 - 5:00 pm EDT </br> 22:30 - 23:00 CEST</td>-->
                            <td>Organizers</td>
                            <td>Openning</td>
                        </tr>

                        <tr onClick='toggleRow(this)'>
                            <td>8:35-9:15</td>
                            <td><strong><a href="http://www.wucathy.com/blog/">Cathy Wu</a></strong></br> Massachusetts
                                Institute of Technology
                            </td>
                            <td> Intelligent Coordination for Sustainable Roadways â€“ If Autonomous Vehicles are the
                                Answer, then What is the Question?
                            </td>
                            <td class='expanded-row-content hide-row'>Abstract: For all its hype, autonomous vehicles
                                have yet to make our roadways more sustainable: safer, cheaper, cleaner. This talk
                                suggests that key to unlocking sustainable roadways is to shift the focus from
                                autonomy-driven design to use-driven design. Based on recent work, the talk focuses on
                                three critical prioritiesâ€“â€“safety, cost, and environmentâ€“â€“each leveraging the 'autonomy'
                                capability of coordinating vehicles. But fully autonomous agents are not the only
                                entities that can coordinate. A paragon of safety is air traffic control, in which
                                expert operators remotely coordinate aircraft. The work brings these ideas to the dense
                                traffic on roadways and analyzes the scalability of operators. Another much cheaper way
                                to coordinate is to give a smartphone app to drivers. The work characterizes how well
                                lower-tech systems can still achieve autonomous capabilities. For cleaner roadways,
                                dozens of articles have considered coordinating vehicles to reduce emissions. This work
                                models whether doing so would move the needle on climate change mitigation goals. To
                                study these multi-agent coordination problems, the work leverages queueing theory,
                                Lyapunov stability analysis, transfer learning, and multi-task reinforcement learning.
                                The talk will also substantiate issues of robustness that arise when applying
                                learning-based techniques and a new line of work designed to address them. Overall, the
                                results indicate promise for intelligent coordination to enable sustainable roadways.
                            </td>
                        </tr>

                        <tr onClick='toggleRow(this)'>
                            <td>9:20-9:50</td>
                            <td><strong><a
                                    href="https://environment.leeds.ac.uk/transport/staff/957/professor-gustav-markkula">Gustav
                                Markkula</a></strong></br>
                                University of Leeds
                            </td>
                            <td> Adopting Knowledge and Models from Cognitive Neuroscience to Enable Socially
                                Interactive Automation
                            </td>
                            <td class='expanded-row-content hide-row'>Abstract: It is becoming increasingly clear that
                                human interaction in traffic is underpinned by a number of non-trivial perceptual,
                                cognitive, and motor mechanisms, which both constrain and determine the behaviour of
                                human road users. In this talk I will give an overview of a number of such mechanisms,
                                which have been mathematically modelled in cognitive neuroscience, and which our team
                                and others have adopted into models of human road user behaviour. Finally, I will
                                discuss to what extent, and for what uses, it may be important to consider these types
                                of underlying human mechanisms in the development and testing of automated vehicles
                            </td>
                        </tr>


                        <tr onClick='toggleRow(this)'>
                            <td>9:55-10:25</td>
                            <td><strong><a href="https://www.gilitschenski.org/igor/">Igor
                                Gilitschenski</a></strong></br>
                                University of Toronto
                            </td>
                            <td> Inductive Biases for Safe Interactive Autonomy
                            </td>
                            <td class='expanded-row-content hide-row'>Abstract:
                            </td>
                        </tr>


                        <tr onClick='toggleRow(this)'>
                            <td>10:30-11:00</td>
                            <td><strong><a
                                    href="https://scholar.google.com/citations?hl=en&user=vcU93tYAAAAJ">Yan
                                Chang</a></strong></br>
                                Zoox
                            </td>
                            <td> Automatic Parameters Tuning for Autonomous Systems
                            </td>
                            <td class='expanded-row-content hide-row'>Abstract: Thousands of parameters need to be tuned
                                across the autonomy stack and beyond for the autonomous driving systems. It's
                                challenging to balance various requirements such as safety, progress, and comfort. In
                                this talk, we will share an Automatic Parameters Tuning System for Autonomous Driving
                                Systems. Four Key takeaways:
                                (1) A generic framework for parameter tuning for different use cases.
                                (2) A scalable framework that can use a large amount of scenes to do the auto-tuning and
                                validation. (3) A modularized architecture. (4) A user-friendly end-to-end interface for
                                experiments, visualization, and analysis.
                            </td>
                        </tr>


                        <tr onClick='toggleRow(this)'>
                            <td>11:05-11:35</td>
                            <td><strong><a href="https://research.nvidia.com/person/yuxiao-chen">Yuxiao
                                Chen</a></strong></br>
                                NVIDIA
                            </td>
                            <td> How to plan with prediction: a policy planning perspective
                            </td>
                            <td class='expanded-row-content hide-row'>Abstract: In a typical autonomous vehicle (AV)
                                stack, motion predictions are consumed by the planning module to generate safe and
                                efficient motion plan for the AV. While deep learning took the field of prediction by
                                storm and kept improving the SOTA of prediction accuracy, it is unclear how they are
                                helping the subsequent motion plan. This talk focuses on how prediction models are used
                                together with the downstream planning module and showed that one key factor to improving
                                the closed-loop performance is via policy planning, that is, planning a motion policy
                                instead of a single trajectory. Our recent works use prediction models to generate
                                scenario trees and then plan tree-structured motion policies capable of reacting to the
                                environment behavior. Thanks to the reactiveness, we showed that policy planning
                                significantly outperforms the traditional benchmarks in closed-loop simulation. As
                                expected, the increased complexity leads to higher computational cost, and we will
                                discuss the limitations of policy planning in the talk as well.
                            </td>
                        </tr>


                        <tr onClick='toggleRow(this)'>
                            <td>11:35-12:05</td>
                            <td><strong><a href="https://www.olgersiebinga.nl/">Olger Siebinga</a></strong></br>
                                Delft University of Technology
                            </td>
                            <td> How Risk Perception and Communication can be used to Model Human Traffic Interactions
                            </td>
                            <td class='expanded-row-content hide-row'>Abstract: Interaction-aware autonomous driving is
                                mostly achieved by including models of human driving behavior in autonomous vehicles.
                                These models can predict the future actions of human traffic participants, and based on
                                this information, the autonomous vehicle can better handle interactions in traffic.
                                However, many of these approaches are based on the concept of Game Theory and therefore
                                make strong assumptions about human behavior. For example, the assumptions that humans
                                are rational, and do not communicate. In this talk, I will present an alternative
                                approach to modeling human behavior in traffic interactions. We will discuss how
                                perceived risk is a driving factor behind human behavior in non-interactive scenarios,
                                and how communication plays an important role in interactions. Combined with Simonâ€™s
                                ideas of bounded rationality and satisficing, these concepts led to our novel modeling
                                approach: the communication-enabled interaction model.
                            </td>
                        </tr>

                        <tr onClick='toggleRow(this)'>
                            <td>12:10-12:40</td>
                            <td><strong><a href="https://krdc.web.illinois.edu/">Katherine
                                Driggs-Campbell</a></strong></br>
                                University of Illinois Urbana-Champaign
                            </td>
                            <td> People as Sensors: A social inference approach for occlusion-aware autonomy
                            </td>
                            <td class='expanded-row-content hide-row'>Abstract: Autonomous vehicles have the potential
                                to change the foundations of our way of life. However, the desirable impacts of autonomy
                                are only achievable if they can effectively interact with human agents and behave in
                                similar ways. One key challenge is operating with limited sensing in partially
                                observable environments, where occluded human agents are prevalent. Humans (often)
                                intuitively infer the presence of occluded obstacles and agents simply by observing how
                                nearby drivers are behaving. Much like humans in the real world who observe other
                                drivers to make inferences, we have designed a framework that treats human drivers as
                                sensors to improve map estimation, as a proxy for detection. Our method handles
                                multi-agent scenarios, combining measurements from multiple observed drivers using
                                evidential theory to solve the sensor fusion problem. We demonstrate our methods on
                                real-world traffic data showing effective inference in complex multi-agent environments
                                and translate deployment to a mobile robot in a crowd navigation setting.
                            </td>
                        </tr>

                        <tr>
                            <td>12:40-12:45</td>
                            <!--                            <td> 4:30 - 5:00 pm EDT </br> 22:30 - 23:00 CEST</td>-->
                            <td>Organizers</td>
                            <td>Discussion and conclusions</td>
                        </tr>

                        </tbody>
                    </table>
                </div>
            </div>
        </section>

        <section id="Invited_Speaker" class="main style1">
            <div class="container">
                <header class="major">
                    <h2>Invited Speakers</h2>
                </header>
                <div class="main-topic">
                    <div class="left-text">
                        <h3><strong><a href="http://www.wucathy.com/blog/">Cathy Wu</a></strong></br> Massachusetts
                            Institute of Technology</h3>
                        <p>
                            Cathy Wu is an Assistant Professor at MIT in LIDS, CEE, and IDSS. She holds a Ph.D. from
                            UC Berkeley, and B.S. and M.Eng. from MIT, all in EECS, and completed a Postdoc at
                            Microsoft Research. Her research interests are at the intersection of machine learning,
                            decision making, and mobility. Her current work focuses on how learning-based methods
                            can advance emerging mobility systems by better coping with the complexity of decisions
                            and control. She is broadly interested in enabling policy-relevant research by pushing
                            the boundaries of learning, control, and optimization. Cathy has received a number of
                            awards, including the NSF CAREER, dissertation awards, and publications with
                            distinctions. Her work has appeared in the press, including NOVA, Wired, Science
                            Magazine, the MIT Homepage, and TEDxMIT.
                        </p>
                    </div>

                    <div class="right-picture">
                        <img src="images/Speakers/Cathy.jpg">
                    </div>

                    <div class="left-text">
                        <h3><strong><a
                                href="https://environment.leeds.ac.uk/transport/staff/957/professor-gustav-markkula">Gustav
                            Markkula</a></strong></br>
                            University of Leeds</h3>
                        <p>
                            Prof. Gustav Markkula is an engineer by training, and applies quantitative methods and
                            models to the study of human behaviour and cognition in road traffic. He has a background in
                            automotive industry R&D (Volvo), and is currently Chair in Applied Behaviour Modelling at
                            the Institute for Transport Studies, University of Leeds, UK. In his research, he
                            specialises in the adoption and integration of models from computational cognitive
                            neuroscience, to support development and testing of safe and human-acceptable technology and
                            automation.
                        </p>
                    </div>

                    <div class="right-picture">
                        <img src="images/Speakers/gustav.jfif">
                    </div>

                    <div class="left-text">
                        <h3><strong><a href="https://www.gilitschenski.org/igor/">Igor
                            Gilitschenski</a></strong></br>
                            University of Toronto</h3>
                        <p>
                            Igor Gilitschenski is an Assistant Professor of Computer Science at the University of
                            Toronto where he leads the Toronto Intelligent Systems Lab. He is also a (part-time)
                            Research Scientist at the Toyota Research Institute. Prior to that, Dr. Gilitschenski was a
                            Research Scientist at MITâ€™s Computer Science and Artificial Intelligence Lab and the
                            Distributed Robotics Lab (DRL) where he was the technical lead of DRLâ€™s autonomous driving
                            research team. He joined MIT from the Autonomous Systems Lab of ETH Zurich where he worked
                            on robotic perception, particularly localization and mapping. Dr. Gilitschenski obtained his
                            doctorate in Computer Science from the Karlsruhe Institute of Technology and a Diploma in
                            Mathematics from the University of Stuttgart. His research interests involve developing
                            novel robotic perception and decision-making methods for challenging dynamic environments.
                            He is the recipient of several best paper awards including at the American Control
                            Conference, the International Conference of Information Fusion, and the Robotics and
                            Automation Letters.</br></br>
                        </p>
                    </div>

                    <div class="right-picture">
                        <img src="images/Speakers/Igor.jpg">
                    </div>

                    <div class="left-text">
                        <h3><strong><a href="https://scholar.google.com/citations?hl=en&user=vcU93tYAAAAJ">Yan Chang</a></strong></br>
                            Zoox</h3>
                        <p>
                            Yan Chang is a Tech Lead Manager and Software Engineer at Zoox, where she applies planning
                            and machine learning techniques to
                            solve autonomous driving for dense urban environments. She serves as an associate editor of
                            IEEE Transactions of Transportation
                            Electrification. She holds a Master degree and Ph.D. degree in Mechanical Engineering from
                            the University of Michigan - Ann Arbor.</br></br></br></br>
                        </p>
                    </div>

                    <div class="right-picture">
                        <img src="images/Speakers/Yan_Chang.jpg">
                    </div>

                    <div class="left-text">
                        <h3><strong><a href="https://research.nvidia.com/person/yuxiao-chen">Yuxiao
                            Chen</a></strong></br>NVIDIA</h3>
                        <p>
                            Yuxiao Chen is a senior research scientist in the autonomous vehicle research group at
                            Nvidia. His research interest includes safe autonomy, motion planning for AV, especially
                            policy planning, and generative AI for closed-loop simulation and scene generation of
                            AV. He did his undergraduate in Tsinghua University, obtained his Ph.D. from the
                            University of Michigan in 2018, and was a postdoc at Caltech from 2018 to 2021. He
                            joined Nvidia research in 2021.</br></br>
                        </p>
                    </div>

                    <div class="right-picture">
                        <img src="images/Speakers/Yuxiao.png">
                    </div>


                    <div class="left-text">
                        <h3><strong><a href="https://www.olgersiebinga.nl/">Olger Siebinga</a></strong></br>
                            Delft University of Technology</h3>
                        <p>
                            Olger Siebinga is a PhD candidate at Delft University of Technology, working in the field of
                            human-robot interaction. With a background in mechanical engineering, he has always been
                            fascinated by the combination of mechanical, electrical, and software engineering. But
                            throwing humans in the mix is what makes things really interesting. Many robots can behave
                            safe and optimal in their own perfect, isolated world. But to make modern robots, such as
                            automated vehicles, function in the real world, they must be able to interact with humans in
                            a safe and natural manner. This is where his current work focuses on: understanding human
                            (driving) behavior and describing it in a mathematical way such that automated vehicles can
                            make decisions based on their understanding of humans.
                        </p>
                    </div>

                    <div class="right-picture">
                        <img src="images/Speakers/olger.jpg">
                    </div>

                    <div class="left-text">
                        <h3><strong><a href="https://krdc.web.illinois.edu/">Katherine
                            Driggs-Campbell</a></strong></br>
                            University of Illinois Urbana-Champaign</h3>
                        <p>
                            Katie Driggs-Campbell is currently an assistant professor and Bruning Faculty Fellow at the
                            University of Illinois at Urbana-Champaign in the Department of Electrical and Computer
                            Engineering. Prior to joining UIUC, she received a B.S.E. with honors from Arizona State
                            University in 2012, a M.S. and PhD from UC Berkeley in 2015 and 2017, respectively, and was
                            a postdoc in the Stanford Intelligent Systems Laboratory. Katie now runs the Human-Centered
                            Autonomy Lab, which aims to design safe autonomous systems and robots that can safely
                            interact with people out in the real-world. She is a recent recipient of the NSF CAREER
                            award and IEEE RAS Early Academic Career Award.
                        </p>
                    </div>

                    <div class="right-picture">
                        <img src="images/Speakers/Katie.jpg">
                    </div>

                </div>


            </div>
        </section>

        <section id="Technical_Committee" class="main style1">
            <div class="container">
                <header class="major">
                    <h2>Technical Committee</h2>
                    <div class="row">
                        <div class="column"><a href="https://www.trailab.utias.utoronto.ca/current-members"><strong>Steven
                            Waslander</strong>, University of Toronto</a></br>
                            <a href="https://jiachengzhuml.github.io/"><strong>Jiacheng
                                Zhu</strong>, Carnegie Mellon University</a></br>
                            <a href="https://www.coe.pku.edu.cn/teaching/all_time/10394.html"><strong>Chang
                                Liu</strong>, Peking University</a></br>
                            <a href="https://ziranw.github.io/"><strong>Ziran Wang</strong>, Purdue University</a></br>
                            <a href="https://www.fshuo.tech/"><strong>Shuo Feng</strong>, University of
                                Michigan</a></br>
                            <a href="https://ruichen.pub/"><strong>Rui Chen</strong>, Carnegie Mellon
                                University</a></br>
                        </div>


                        <div class="column"><a href="https://unhelkar.github.io/"><strong>Vaibhav Unhelkar</strong>,
                            Rice
                            University</a></br>
                            <a href="https://yeping-hu.github.io/"><strong>Yeping Hu</strong>, Lawrence Livermore
                                National Laboratory</a></br>
                            <a href="https://pure.qub.ac.uk/en/persons/chongfeng-wei"><strong>Chongfeng Wei</strong>,
                                Queen's University Belfast</a></br>
                            <a href="https://idsc.ethz.ch/research-frazzoli/people/person-detail.MjIxNjc1.TGlzdC8yNjg5LDQ4ODg4MTE2Mw==.html"><strong>Alessandro
                                Zanardi</strong>, ETH ZÃ¼rich</a></br>
                            <a href="https://gioele.science/"><strong>Gioele Zardini</strong>, ETH ZÃ¼rich</a></br>
                            <a href="https://xushengluo92.github.io/"><strong>Xusheng Luo</strong>, Carnegie Mellon
                                University</a></br>
                        </div>
                    </div>
                </header>
            </div>
        </section>


        <section id="organizers" class="main style1">
            <div class="container">

                <header class="major">
                    <h2>Organizers</h2>
                </header>


                <div class="box alt">
                    <div class="row gtr-round">
                        <div class="col-2">
                            <img class="circular-square" src="images/Organizers/Wenshuo_Wang.jpg"
                                 alt=""/>
                            <h5><a href="https://wenshuowang.github.io/"><strong>Dr. Wenshuo Wang</strong></br> McGill
                                University</a></h5>
                        </div>

                        <div class="col-2">
                            <img class="circular-square" src="images/Organizers/Jiachen_li.jpg"
                                 alt=""/>
                            <h5><a href="https://jiachenli94.github.io"><strong>Dr. Jiachen Li</strong></br> Stanford
                                University</a></h5>
                        </div>

                        <div class="col-2">
                            <img class="circular-square" src="images/Organizers/Chengyuan_Zhang.jpg"/>
                            <h5><a href="https://chengyuan-zhang.github.io/"><strong>Chengyuan Zhang</strong></br>
                                McGill University</a></h5>
                        </div>

                        <div class="col-2">
                            <img class="circular-square" src="images/Organizers/Letian_Wang.jpg"/>
                            <h5><a href="https://letianwang0.wixsite.com/myhome"><strong>Letian Wang</strong></br>
                                University of Toronto</a></h5>
                        </div>

                        <div class="col-2">
                            <img class="circular-square" src="images/Organizers/daniel_omeiza.jpg"/>
                            <h5><a href="https://danielomeiza.github.io/"><strong>Daniel Omeiza</strong></br>
                                University of Oxford</a></h5>
                        </div>

                        <div class="col-2">
                            <img class="circular-square" src="images/Organizers/Mushuang_Liu.jpg"/>
                            <h5><a href="https://engineering.missouri.edu/faculty/mushuang-liu/"><strong>Prof. Mushuang
                                Liu</strong></br>
                                University of Missouri</a></h5>
                        </div>

                        <div class="col-2">
                            <img class="circular-square" src="images/Organizers/Changliu_Liu.jpg"/>
                            <h5><a href="http://www.cs.cmu.edu/~cliu6/index.html"><strong>Prof. Changliu
                                Liu</strong></br>
                                Carnegie Mellon University</a></h5>
                        </div>

                        <div class="col-2">
                            <img class="circular-square" src="images/Organizers/Lijun_Sun.jpg"/>
                            <h5><a href="https://lijunsun.github.io/"><strong>Prof. Lijun Sun</strong></br>
                                McGill University</a></h5>
                        </div>


                    </div>
                </div>
                </br>
        </section>

        <section id="support" class="main style1">
            <header class="major">
                <h2>Supported by</h2>
            </header>
            <div class="container">
                <div class="row gtr-uniform">
                    <div class="col-2"><span class="image fit"><img
                            src="images/Affiliations/McGill.png"
                            alt=""/></span>
                    </div>

                    <div class="col-2"><span class="image fit"><img
                            src="images/Affiliations/Stanford.png"
                            alt=""/></span>
                    </div>
                    <div class="col-2"><span class="image fit"><img
                            src="images/Affiliations/university-of-toronto.png"
                            alt=""/></span>
                    </div>
                    <div class="col-2"><span class="image fit"><img
                            src="images/Affiliations/cmu.png"
                            alt=""/></span>
                    </div>
                    <div class="col-2"><span class="image fit"><img
                            src="images/Affiliations/University_of_Missouri.jpg"
                            alt=""/></span>
                    </div>
                    <div class="col-2"><span class="image fit"><img
                            src="images/Affiliations/University-of-Oxford.png"
                            alt=""/></span>
                    </div>
                    <div class="col-2"><span class="image fit"><img
                            src="images/Affiliations/IEEE-ITSS-logo.png"
                            alt=""/></span>
                    </div>
                </div>
            </div>
    </div>
    </section>


</div>

<!-- Footer -->
<footer id="footer">
    <!--        <section>-->
    <!--            <h2>Get in touch</h2>-->
    <!--            <p>Please feel free to send us an <a href="mailto:wwsbit@gmail.com"-->
    <!--                                                 target="_top">e-mail</a> , if you have any questions regarding this-->
    <!--                workshop.</p>-->
    <!--        </section>-->

    <!--        <section>-->
    <!--            <h2>Etiam feugiat</h2>-->
    <!--            <dl class="alt">-->
    <!--                <dt>Address</dt>-->
    <!--                <dd>1234 Somewhere Road &bull; Nashville, TN 00000 &bull; USA</dd>-->
    <!--                <dt>Phone</dt>-->
    <!--                <dd>(000) 000-0000 x 0000</dd>-->
    <!--                <dt>Email</dt>-->
    <!--                <dd><a href="#">information@untitled.tld</a></dd>-->
    <!--            </dl>-->
    <!--            <ul class="icons">-->
    <!--                <li><a href="#" class="icon brands fa-twitter alt"><span class="label">Twitter</span></a></li>-->
    <!--                <li><a href="#" class="icon brands fa-facebook-f alt"><span class="label">Facebook</span></a></li>-->
    <!--                <li><a href="#" class="icon brands fa-instagram alt"><span class="label">Instagram</span></a></li>-->
    <!--                <li><a href="#" class="icon brands fa-github alt"><span class="label">GitHub</span></a></li>-->
    <!--                <li><a href="#" class="icon brands fa-dribbble alt"><span class="label">Dribbble</span></a></li>-->
    <!--            </ul>-->
    <!--        </section>-->

    <p class="copyright">&copy; Chengyuan Zhang and Wenshuo Wang. All rights reserved. Design: <a
            href="https://html5up.net">HTML5 UP</a>.<br>
        <span id="busuanzi_container_site_uv">
      <span id="busuanzi_value_site_uv"></span> <span>vistors</span>
    </span>&<span id="busuanzi_container_site_pv">
      <span id="busuanzi_value_site_pv"></span> <span>views since December 2022.</span>
        </span></p>
</footer>

</div>

<!-- Scripts -->
<script src="assets/js/jquery.min.js"></script>
<script src="assets/js/jquery.scrollex.min.js"></script>
<script src="assets/js/jquery.scrolly.min.js"></script>
<script src="assets/js/browser.min.js"></script>
<script src="assets/js/breakpoints.min.js"></script>
<script src="assets/js/util.js"></script>
<script src="assets/js/main.js"></script>

<script>
    const toggleRow = (element) => {
        element.getElementsByClassName('expanded-row-content')[0].classList.toggle('hide-row');
        console.log(event);
    }
</script>
<script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

</body>
</html>
